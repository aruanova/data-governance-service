# Panel-Datainspector - Plan de Refactorizaci√≥n (Monorepo)

## üìã Estado Actual
- **Stack Backend**: FastAPI + Celery + Redis + PostgreSQL + OpenAI
- **Stack Frontend**: Next.js 15.3.5 + React 19 + TypeScript
- **Prop√≥sito**: Clasificaci√≥n de l√≠neas CFDI usando LLM con refinamiento iterativo
- **Complejidad**: 12 routers, 25+ servicios, procesamiento async distribuido

## üéØ Objetivos de la Refactorizaci√≥n
1. Migrar backend de Python/FastAPI a Go
2. Cambiar a Svelte con Skeleton (solo ajustar endpoints si es necesario)
3. Estructura monorepo para facilitar desarrollo
4. Mejorar performance y reducir uso de memoria
5. Simplificar arquitectura manteniendo funcionalidad completa

## üèóÔ∏è Estructura Monorepo Propuesta

```
data-governance-service/
‚îú‚îÄ‚îÄ .claude/                    # Documentaci√≥n y contexto de Claude
‚îÇ   ‚îú‚îÄ‚îÄ PLANNING.md
‚îÇ   ‚îî‚îÄ‚îÄ CLAUDE.md
‚îú‚îÄ‚îÄ backend/                    # Backend en Go
‚îÇ   ‚îú‚îÄ‚îÄ cmd/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/               # API REST server
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ worker/            # Worker para procesamiento async
‚îÇ   ‚îú‚îÄ‚îÄ internal/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/               # HTTP handlers
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ handlers/      # Controladores REST
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ middleware/    # Auth, CORS, logging
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ websocket/     # WebSocket handlers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core/              # Dominio central
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/        # Modelos de dominio
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ports/         # Interfaces (hexagonal)
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ services/      # L√≥gica de negocio
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ infrastructure/    # Implementaciones externas
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database/      # PostgreSQL
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cache/         # Redis
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ storage/       # File system / S3
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm/           # OpenAI client
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ queue/         # Task queue (Asynq)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pkg/               # Utilidades compartidas
‚îÇ   ‚îú‚îÄ‚îÄ migrations/            # SQL migrations
‚îÇ   ‚îú‚îÄ‚îÄ configs/               # Configuraciones
‚îÇ   ‚îî‚îÄ‚îÄ tests/                 # Tests de integraci√≥n
‚îú‚îÄ‚îÄ frontend/                  # Frontend (A definir si Svelte)
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îî‚îÄ‚îÄ public/
‚îú‚îÄ‚îÄ shared/                    # Compartido entre front y back
‚îÇ   ‚îú‚îÄ‚îÄ types/                # TypeScript types que matchean Go structs
‚îÇ   ‚îî‚îÄ‚îÄ api-spec/             # OpenAPI/Swagger specs
‚îú‚îÄ‚îÄ scripts/                   # Scripts de build y deployment
‚îú‚îÄ‚îÄ docker/                    # Dockerfiles y compose
‚îú‚îÄ‚îÄ .github/                   # CI/CD workflows
‚îî‚îÄ‚îÄ docs/                      # Documentaci√≥n del proyecto
```

## üîÑ Servicios Go Propuestos

### 1. API Service (backend/cmd/api)
- **Responsabilidad**: Exponer REST API, manejar uploads, WebSockets
- **Puertos**: 8080 (HTTP), 8081 (WebSocket)
- **Similar a routers Python**: pipeline.py, cleaning.py, validation.py, batch.py

### 2. Worker Service (backend/cmd/worker)
- **Responsabilidad**: Procesar tareas async, LLM calls, batch processing
- **Similar a**: Celery workers actuales
- **Queue**: Asynq (Redis-based) o Temporal
- **Resiliencia**: Checkpointing, health checks, graceful shutdown

### 3. Servicios de Dominio (backend/internal/core/services)
```
services/
‚îú‚îÄ‚îÄ upload/              # Gesti√≥n de uploads y archivos ZIP
‚îú‚îÄ‚îÄ schema_inspector/    # Inspecci√≥n y an√°lisis de archivos
‚îú‚îÄ‚îÄ refinery/           # Sistema modular de limpieza de texto
‚îÇ   ‚îú‚îÄ‚îÄ v1_standard/    # Versi√≥n para datos mexicanos
‚îÇ   ‚îú‚îÄ‚îÄ v2_aggressive/  # Limpieza m√°s agresiva
‚îÇ   ‚îî‚îÄ‚îÄ registry/       # Registro de versiones
‚îú‚îÄ‚îÄ cleaning/           # Limpieza y deduplicaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ deduplication/  # Sistema two-level de dedup
‚îÇ   ‚îî‚îÄ‚îÄ json_generator/ # Generador de JSON para LLM
‚îú‚îÄ‚îÄ prompts/            # Gesti√≥n de prompts customizables
‚îÇ   ‚îú‚îÄ‚îÄ storage/        # Almacenamiento de prompts
‚îÇ   ‚îî‚îÄ‚îÄ versioning/     # Versionado de prompts
‚îú‚îÄ‚îÄ llm/               # Clasificaci√≥n con LLM
‚îú‚îÄ‚îÄ validation/        # Muestreo y validaci√≥n
‚îú‚îÄ‚îÄ batch/             # Procesamiento multi-archivo
‚îú‚îÄ‚îÄ iteration/         # Tracking de iteraciones
‚îú‚îÄ‚îÄ metrics/           # Captura de m√©tricas
‚îú‚îÄ‚îÄ checkpoint/        # Sistema de checkpointing
‚îú‚îÄ‚îÄ recovery/          # Recuperaci√≥n de trabajos fallidos
‚îî‚îÄ‚îÄ session/           # Gesti√≥n de sesiones
```

## üìä Flujo de Procesamiento de Archivos

### Pipeline Pre-LLM
```mermaid
graph LR
    A[Upload ZIP] --> B[Schema Inspection]
    B --> C[Refinery Cleaning]
    C --> D[Deduplication]
    D --> E[JSON Generation]
    E --> F[LLM Processing]
```

### Etapas Detalladas

#### 1. Upload & Extracci√≥n
- Recepci√≥n de archivos ZIP con m√∫ltiples formatos
- Soporte para: CSV, XLSX, JSON, JSONL, NDJSON
- Streaming para archivos grandes
- Validaci√≥n de esquemas

#### 2. Schema Inspection
- Detecci√≥n autom√°tica de columnas
- Inferencia de tipos de datos
- An√°lisis de calidad de datos
- Sampling para preview

#### 3. Refinery (Sistema Modular)
- **Arquitectura Plugin**: Versiones intercambiables
- **v1-standard**: Limpieza para datos mexicanos
- **v2-aggressive**: Limpieza m√°s estricta
- **Nodos de Procesamiento**:
  - Remover c√≥digos con prefijos (ART###)
  - Remover meses en espa√±ol
  - Normalizaci√≥n de caracteres especiales
  - Remover palabras cortas
  - Aplicar whitelist/blacklist

#### 4. Deduplicaci√≥n Two-Level
- **Nivel 1**: Deduplicaci√≥n dentro del batch
- **Nivel 2**: Deduplicaci√≥n universal (cross-session)
- Estrategias: exact, fuzzy, universal
- Usa columnas "clean" generadas por Refinery

#### 5. JSON Generation
- Creaci√≥n de estructura optimizada para LLM
- Inclusi√≥n de _row_index para tracking
- Solo campos "clean" para reducir tokens
- Metadata para contexto

## ü§ñ Sistema Multi-Proveedor LLM

### Proveedores Soportados
- **OpenAI**: GPT-4, GPT-4o-mini, GPT-3.5-turbo
- **Google Gemini**: Gemini-Pro, Gemini-1.5-Pro
- **Extensible**: Factory pattern para agregar nuevos proveedores

### Caracter√≠sticas
- **Selecci√≥n Din√°mica**: Usuario escoge proveedor por request
- **Fallback Autom√°tico**: Si un proveedor falla, notificar al usuario y darle a escoger usar una alternativa
- **Configuraci√≥n por Proveedor**:
  - API Keys independientes
  - Modelos espec√≠ficos
  - Rate limits y retry policies
- **M√©tricas Comparativas**:
  - Tiempo de respuesta
  - Costo por tokens
  - Calidad de clasificaci√≥n

## üé® Sistema de Prompts Customizables

### Caracter√≠sticas Clave
- **100% Customizable**: NO hay prompt default
- **Gesti√≥n de Prompts**:
  - Crear, editar, eliminar prompts
  - Asignar labels descriptivos
  - Versionado autom√°tico
  - Compartir entre usuarios
- **Categor√≠as Din√°micas**:
  - Usuario define sus propias categor√≠as
  - Puede importar/exportar sets de categor√≠as
  - Prioridades configurables
- **Storage**:
  - PostgreSQL para persistencia
  - Redis para cache
  - Historial de versiones

### Estructura de Prompt
```json
{
  "id": "uuid",
  "name": "Mi Prompt OXXO v3",
  "label": "Clasificaci√≥n gastos OXXO 2024",
  "template": "Texto del prompt customizado...",
  "categories": [
    {
      "id": 1,
      "name": "Categor√≠a Custom 1",
      "description": "Descripci√≥n",
      "keywords": ["palabra1", "palabra2"]
    }
  ],
  "created_by": "user_id",
  "version": 3,
  "is_active": true
}
```

## üìä Fases de Migraci√≥n

### Fase 0: Setup Monorepo (Semana 1)
- [x] Crear estructura .claude
- [ ] Definir estructura de carpetas
- [ ] Setup Go modules
- [ ] Configurar herramientas (linters, formatters)
- [ ] Docker Compose para desarrollo

### Fase 1: Core Infrastructure (Semana 2)
- [ ] Conexi√≥n PostgreSQL con pgx
- [ ] Conexi√≥n Redis
- [ ] Logging estructurado (slog)
- [ ] Config management (viper)
- [ ] Migrations setup (golang-migrate)

### Fase 2: Upload & Cleaning Pipeline (Semana 3-4)
- [ ] Upload de archivos (Excel/CSV/JSON)
- [ ] Parsing streaming de archivos grandes
- [ ] Pipeline de limpieza (refinery v3)
- [ ] Deduplicaci√≥n universal
- [ ] Generaci√≥n de JSON para LLM

### Fase 3: LLM Integration (Semana 5-6)
- [ ] Cliente OpenAI
- [ ] Cliente Gemini
- [ ] Chunking din√°mico configurable (LLM_DISTRIBUTED_CHUNK_SIZE)
- [ ] Worker pool configurable para procesamiento paralelo
- [ ] Manejo de respuestas y normalizaci√≥n
- [ ] Count mismatch handling
- [ ] Retry logic con backoff

### Fase 4: Task Queue System (Semana 7-8)
- [ ] Setup Asynq o Temporal
- [ ] Migrar l√≥gica de Celery tasks
- [ ] Progress tracking
- [ ] WebSocket updates

### Fase 5: Validation & Refinement (Semana 9-10)
- [ ] Sampling strategies
- [ ] Validation submission
- [ ] Prompt refinement
- [ ] Iteration tracking
- [ ] Comparative metrics

### Fase 6: Batch Processing (Semana 11-12)
- [ ] Directory scanning
- [ ] Schema validation
- [ ] Multi-file processing
- [ ] Consolidation
- [ ] Streaming para archivos grandes

## üõ†Ô∏è Stack Tecnol√≥gico Definitivo

### Backend (Go)
- **Web Framework**: Gin
- **Task Queue**: Asynq (simple, Redis)
- **Database**: GORM (ORM completo)
- **Cache**: go-redis/v9
- **LLM Providers**:
  - OpenAI: sashabaranov/go-openai
  - Gemini: google/generative-ai-go
  - Factory Pattern para multi-proveedor
- **Excel**: excelize/v2
- **Validation**: go-playground/validator/v10
- **Config**: spf13/viper
- **Logging**: slog (stdlib)
- **Metrics**: Prometheus

### Infraestructura
- **PostgreSQL**: v15+ (igual que actual)
- **Redis**: v7+ (igual que actual)
- **Docker**: Multi-stage builds
- **CI/CD**: GitHub Actions

## ‚ùì Decisiones T√©cnicas Pendientes

### Alta Prioridad
1. **Web Framework**:
   - Gin (popular, buen balance)

2. **Task Queue**:
   - Asynq (simple, suficiente para el caso)

3. **SQL Approach**:
   - GORM (ORM completo)

### Media Prioridad
4. **Estructura del c√≥digo**:
   - Hexagonal/Clean Architecture

5. **Testing Strategy**:
   - ¬øtestify para assertions?
   - ¬ømockery para mocks?
   - ¬øtestcontainers para integration?

## üéØ Optimizaciones Clave vs Python

### Performance
```go
// Streaming de archivos grandes sin cargar en memoria
func ProcessLargeFile(reader io.Reader) error {
    scanner := bufio.NewScanner(reader)
    batch := make([]Record, 0, 1000)

    for scanner.Scan() {
        record := ParseRecord(scanner.Text())
        batch = append(batch, record)

        if len(batch) >= 1000 {
            processBatch(batch)
            batch = batch[:0] // reuse slice
        }
    }
}
```

### Concurrencia Real
```go
// Procesamiento paralelo de chunks con workers pool
func ProcessChunks(chunks []Chunk) {
    workers := runtime.NumCPU()
    ch := make(chan Chunk, len(chunks))
    var wg sync.WaitGroup

    // Worker pool
    for i := 0; i < workers; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            for chunk := range ch {
                processWithLLM(chunk)
            }
        }()
    }

    // Feed work
    for _, chunk := range chunks {
        ch <- chunk
    }
    close(ch)
    wg.Wait()
}
```

## üìà M√©tricas de √âxito
- [ ] 50% reducci√≥n en uso de memoria
- [ ] 2x mejora en throughput
- [ ] <100ms latencia P95 en API
- [ ] 80% cobertura de tests
- [ ] Zero downtime durante migraci√≥n

## üöÄ Pr√≥ximos Pasos Inmediatos
1. ‚úÖ Crear estructura .claude
2. Definir decisiones t√©cnicas clave
3. Crear CLAUDE.md con convenciones
4. Setup inicial del proyecto Go
5. Implementar primer endpoint como POC

## üìù Notas Importantes
- Frontend se redise√±a con Svelte/Skeleton
- API debe mantener compatibilidad con frontend actual
- Aprovechar monorepo para compartir tipos/specs
- Deployment sera usa