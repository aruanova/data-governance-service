# Panel-Datainspector - Plan de Refactorizaci√≥n (Monorepo)

## üìã Estado Actual
- **Stack Backend**: FastAPI + Celery + Redis + PostgreSQL + OpenAI
- **Stack Frontend**: Next.js 15.3.5 + React 19 + TypeScript
- **Prop√≥sito**: Clasificaci√≥n de l√≠neas CFDI usando LLM con refinamiento iterativo
- **Complejidad**: 12 routers, 25+ servicios, procesamiento async distribuido

## üéØ Objetivos de la Refactorizaci√≥n
1. Migrar backend de Python/FastAPI a Go
2. Cambiar a Svelte con Skeleton (solo ajustar endpoints si es necesario)
3. Estructura monorepo para facilitar desarrollo
4. Mejorar performance y reducir uso de memoria
5. Simplificar arquitectura manteniendo funcionalidad completa

## üèóÔ∏è Estructura Monorepo Propuesta

```
data-governance-service/
‚îú‚îÄ‚îÄ .claude/                    # Documentaci√≥n y contexto de Claude
‚îÇ   ‚îú‚îÄ‚îÄ PLANNING.md
‚îÇ   ‚îî‚îÄ‚îÄ CLAUDE.md
‚îú‚îÄ‚îÄ backend/                    # Backend en Go
‚îÇ   ‚îú‚îÄ‚îÄ cmd/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/               # API REST server
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ worker/            # Worker para procesamiento async
‚îÇ   ‚îú‚îÄ‚îÄ internal/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/               # HTTP handlers
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ handlers/      # Controladores REST
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ middleware/    # Auth, CORS, logging
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ websocket/     # WebSocket handlers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core/              # Dominio central
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/        # Modelos de dominio
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ports/         # Interfaces (hexagonal)
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ services/      # L√≥gica de negocio
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ infrastructure/    # Implementaciones externas
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database/      # PostgreSQL
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cache/         # Redis
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ storage/       # File system / S3
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm/           # OpenAI client
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ queue/         # Task queue (Asynq)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pkg/               # Utilidades compartidas
‚îÇ   ‚îú‚îÄ‚îÄ migrations/            # SQL migrations
‚îÇ   ‚îú‚îÄ‚îÄ configs/               # Configuraciones
‚îÇ   ‚îî‚îÄ‚îÄ tests/                 # Tests de integraci√≥n
‚îú‚îÄ‚îÄ frontend/                  # Frontend (A definir si Svelte)
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îî‚îÄ‚îÄ public/
‚îú‚îÄ‚îÄ shared/                    # Compartido entre front y back
‚îÇ   ‚îú‚îÄ‚îÄ types/                # TypeScript types que matchean Go structs
‚îÇ   ‚îî‚îÄ‚îÄ api-spec/             # OpenAPI/Swagger specs
‚îú‚îÄ‚îÄ scripts/                   # Scripts de build y deployment
‚îú‚îÄ‚îÄ docker/                    # Dockerfiles y compose
‚îú‚îÄ‚îÄ .github/                   # CI/CD workflows
‚îî‚îÄ‚îÄ docs/                      # Documentaci√≥n del proyecto
```

## üîÑ Servicios Go Propuestos

### 1. API Service (backend/cmd/api)
- **Responsabilidad**: Exponer REST API, manejar uploads, WebSockets
- **Puertos**: 8080 (HTTP), 8081 (WebSocket)
- **Similar a routers Python**: pipeline.py, cleaning.py, validation.py, batch.py

### 2. Worker Service (backend/cmd/worker)
- **Responsabilidad**: Procesar tareas async, LLM calls, batch processing
- **Similar a**: Celery workers actuales
- **Queue**: Asynq (Redis-based) o Temporal
- **Resiliencia**: Checkpointing, health checks, graceful shutdown

### 3. Servicios de Dominio (backend/internal/core/services)
```
services/
‚îú‚îÄ‚îÄ upload/              # Gesti√≥n de uploads y archivos ZIP
‚îú‚îÄ‚îÄ schema_inspector/    # Inspecci√≥n y an√°lisis de archivos
‚îú‚îÄ‚îÄ refinery/           # Sistema modular de limpieza de texto
‚îÇ   ‚îú‚îÄ‚îÄ v1_standard/    # Versi√≥n para datos mexicanos
‚îÇ   ‚îú‚îÄ‚îÄ v2_aggressive/  # Limpieza m√°s agresiva
‚îÇ   ‚îî‚îÄ‚îÄ registry/       # Registro de versiones
‚îú‚îÄ‚îÄ cleaning/           # Limpieza y deduplicaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ deduplication/  # Sistema two-level de dedup
‚îÇ   ‚îî‚îÄ‚îÄ json_generator/ # Generador de JSON para LLM
‚îú‚îÄ‚îÄ prompts/            # Gesti√≥n de prompts customizables
‚îÇ   ‚îú‚îÄ‚îÄ storage/        # Almacenamiento de prompts
‚îÇ   ‚îî‚îÄ‚îÄ versioning/     # Versionado de prompts
‚îú‚îÄ‚îÄ llm/               # Clasificaci√≥n con LLM
‚îú‚îÄ‚îÄ validation/        # Muestreo y validaci√≥n
‚îú‚îÄ‚îÄ batch/             # Procesamiento multi-archivo
‚îú‚îÄ‚îÄ iteration/         # Tracking de iteraciones
‚îú‚îÄ‚îÄ metrics/           # Captura de m√©tricas
‚îú‚îÄ‚îÄ checkpoint/        # Sistema de checkpointing
‚îú‚îÄ‚îÄ recovery/          # Recuperaci√≥n de trabajos fallidos
‚îî‚îÄ‚îÄ session/           # Gesti√≥n de sesiones
```

## üìä Flujo de Procesamiento de Archivos

### Pipeline Pre-LLM
```mermaid
graph LR
    A[Upload ZIP] --> B[Schema Inspection]
    B --> C[Refinery Cleaning]
    C --> D[Deduplication]
    D --> E[JSON Generation]
    E --> F[LLM Processing]
```

### Etapas Detalladas

#### 1. Upload & Extracci√≥n
- Recepci√≥n de archivos ZIP con m√∫ltiples formatos
- Soporte para: CSV, XLSX, JSON, JSONL, NDJSON, JSONNL
- Streaming para archivos grandes
- Validaci√≥n de esquemas

#### 2. Schema Inspection
- Detecci√≥n autom√°tica de columnas
- Inferencia de tipos de datos
- An√°lisis de calidad de datos
- Sampling para preview

#### 3. Refinery (Sistema Modular)
- **Arquitectura Plugin**: Versiones intercambiables
- **v1-standard**: Limpieza para datos mexicanos
- **v2-aggressive**: Limpieza m√°s estricta
- **Nodos de Procesamiento**:
  - Remover c√≥digos con prefijos (ART###)
  - Remover meses en espa√±ol
  - Normalizaci√≥n de caracteres especiales
  - Remover palabras cortas
  - Aplicar whitelist/blacklist

#### 4. Deduplicaci√≥n Two-Level
- **Nivel 1**: Deduplicaci√≥n dentro del batch
- **Nivel 2**: Deduplicaci√≥n universal (cross-session)
- Estrategias: exact, fuzzy, universal
- Usa columnas "clean" generadas por Refinery

#### 5. JSON Generation
- Creaci√≥n de estructura optimizada para LLM
- Inclusi√≥n de _row_index para tracking
- Solo campos "clean" para reducir tokens
- Metadata para contexto

## ü§ñ Sistema Multi-Proveedor LLM

### Proveedores Soportados
- **OpenAI**: GPT-4, GPT-4o-mini, GPT-3.5-turbo
- **Google Gemini**: Gemini-Pro, Gemini-1.5-Pro
- **Extensible**: Factory pattern para agregar nuevos proveedores

### Caracter√≠sticas
- **Selecci√≥n Din√°mica**: Usuario escoge proveedor por request
- **Fallback Autom√°tico**: Si un proveedor falla, notificar al usuario y darle a escoger usar una alternativa
- **Configuraci√≥n por Proveedor**:
  - API Keys independientes
  - Modelos espec√≠ficos
  - Rate limits y retry policies
- **M√©tricas Comparativas**:
  - Tiempo de respuesta
  - Costo por tokens
  - Calidad de clasificaci√≥n

## üé® Sistema de Prompts Customizables

### Caracter√≠sticas Clave
- **100% Customizable**: NO hay prompt default
- **Gesti√≥n de Prompts**:
  - Crear, editar, eliminar prompts
  - Asignar labels descriptivos
  - Versionado autom√°tico
  - Compartir entre usuarios
- **Categor√≠as Din√°micas**:
  - Usuario define sus propias categor√≠as
  - Puede importar/exportar sets de categor√≠as
  - Prioridades configurables
- **Storage**:
  - PostgreSQL para persistencia
  - Redis para cache
  - Historial de versiones

### Estructura de Prompt
```json
{
  "id": "uuid",
  "name": "Mi Prompt OXXO v3",
  "label": "Clasificaci√≥n gastos OXXO 2024",
  "template": "Texto del prompt customizado...",
  "categories": [
    {
      "id": 1,
      "name": "Categor√≠a Custom 1",
      "description": "Descripci√≥n",
      "keywords": ["palabra1", "palabra2"]
    }
  ],
  "created_by": "user_id",
  "version": 3,
  "is_active": true
}
```

## üìä Fases de Migraci√≥n

### Fase 0: Setup Monorepo ‚úÖ COMPLETADA
- [x] Crear estructura .claude
- [x] Definir estructura de carpetas
- [x] Setup Go modules
- [x] Configurar herramientas (air para hot reload)
- [ ] Docker Compose para desarrollo (pendiente)

### Fase 1: Core Infrastructure ‚úÖ COMPLETADA
- [x] Conexi√≥n PostgreSQL con GORM (cambio de pgx a GORM)
- [x] Conexi√≥n Redis (go-redis/v9)
- [x] Logging estructurado (slog)
- [x] Config management (viper)
- [x] Migrations setup (SQL migrations manuales)
- [x] Task Queue (Asynq)
- [x] Domain models (7 modelos con GORM)
- [x] Testing setup (testcontainers-go con PostgreSQL)

### Fase 2: Upload & Cleaning Pipeline ‚úÖ COMPLETADA (100%)
- [x] Storage local para uploads (FileMetadata, SHA256 hashing, cleanup - 9 tests)
- [x] Parsers de archivos multi-formato (CSV, Excel, JSON, JSONL, NDJSON, JSONNL - 27 tests)
- [x] Parsing streaming de archivos grandes (buffers configurables, context-aware)
- [x] Pipeline de limpieza (Refinery v1 - 42 tests pasando)
- [x] Deduplicaci√≥n universal (two-level: batch + cross-session - 10 tests)
- [x] Generaci√≥n de JSON para LLM (21 tests - token-optimized, chunking, validation)

### Fase 3: LLM Integration (Semana 5-6)
- [ ] Cliente OpenAI
- [ ] Cliente Gemini
- [ ] Chunking din√°mico configurable (LLM_DISTRIBUTED_CHUNK_SIZE)
- [ ] Worker pool configurable para procesamiento paralelo
- [ ] Manejo de respuestas y normalizaci√≥n
- [ ] Count mismatch handling
- [ ] Retry logic con backoff

### Fase 4: Task Queue System ‚ö†Ô∏è PARCIAL
- [x] Setup Asynq (ya implementado en Fase 1)
- [ ] Migrar l√≥gica de Celery tasks
- [ ] Progress tracking
- [ ] WebSocket updates

### Fase 5: Validation & Refinement (Semana 9-10)
- [ ] Sampling strategies
- [ ] Validation submission
- [ ] Prompt refinement
- [ ] Iteration tracking
- [ ] Comparative metrics

### Fase 6: Batch Processing (Semana 11-12)
- [ ] Directory scanning
- [ ] Schema validation
- [ ] Multi-file processing
- [ ] Consolidation
- [ ] Streaming para archivos grandes

## üõ†Ô∏è Stack Tecnol√≥gico Definitivo

### Backend (Go)
- **Web Framework**: Gin
- **Task Queue**: Asynq (simple, Redis)
- **Database**: GORM (ORM completo)
- **Cache**: go-redis/v9
- **LLM Providers**:
  - OpenAI: sashabaranov/go-openai
  - Gemini: google/generative-ai-go
  - Factory Pattern para multi-proveedor
- **Excel**: excelize/v2
- **Validation**: go-playground/validator/v10
- **Config**: spf13/viper
- **Logging**: slog (stdlib)
- **Metrics**: Prometheus

### Infraestructura
- **PostgreSQL**: v15+ (igual que actual)
- **Redis**: v7+ (igual que actual)
- **Docker**: Multi-stage builds
- **CI/CD**: GitHub Actions

## ‚ùì Decisiones T√©cnicas Pendientes

### Alta Prioridad
1. **Web Framework**:
   - Gin (popular, buen balance)

2. **Task Queue**:
   - Asynq (simple, suficiente para el caso)

3. **SQL Approach**:
   - GORM (ORM completo)

### Media Prioridad ‚úÖ RESUELTAS
4. **Estructura del c√≥digo**:
   - ‚úÖ Hexagonal/Clean Architecture (implementada)

5. **Testing Strategy**:
   - ‚úÖ testify para assertions (implementado)
   - ‚è≥ mockery para mocks (pendiente)
   - ‚úÖ testcontainers para integration (implementado)

## üéØ Optimizaciones Clave vs Python

### Performance
```go
// Streaming de archivos grandes sin cargar en memoria
func ProcessLargeFile(reader io.Reader) error {
    scanner := bufio.NewScanner(reader)
    batch := make([]Record, 0, 1000)

    for scanner.Scan() {
        record := ParseRecord(scanner.Text())
        batch = append(batch, record)

        if len(batch) >= 1000 {
            processBatch(batch)
            batch = batch[:0] // reuse slice
        }
    }
}
```

### Concurrencia Real
```go
// Procesamiento paralelo de chunks con workers pool
func ProcessChunks(chunks []Chunk) {
    workers := runtime.NumCPU()
    ch := make(chan Chunk, len(chunks))
    var wg sync.WaitGroup

    // Worker pool
    for i := 0; i < workers; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            for chunk := range ch {
                processWithLLM(chunk)
            }
        }()
    }

    // Feed work
    for _, chunk := range chunks {
        ch <- chunk
    }
    close(ch)
    wg.Wait()
}
```

## üìà M√©tricas de √âxito
- [ ] 50% reducci√≥n en uso de memoria
- [ ] 2x mejora en throughput
- [ ] <100ms latencia P95 en API
- [ ] 80% cobertura de tests
- [ ] Zero downtime durante migraci√≥n

## üöÄ Pr√≥ximos Pasos Inmediatos
1. ‚úÖ Crear estructura .claude
2. Definir decisiones t√©cnicas clave
3. Crear CLAUDE.md con convenciones
4. Setup inicial del proyecto Go
5. Implementar primer endpoint como POC

## üìù Notas Importantes
- Frontend se redise√±a con Svelte/Skeleton
- API debe mantener compatibilidad con frontend actual
- Aprovechar monorepo para compartir tipos/specs
- Deployment ser√° en AWS/GCP

---

## üéØ CHECKPOINT #2 - File Processing & Parsers (17 Oct 2025)

### ‚úÖ Completado en esta sesi√≥n

#### 1. **Local Storage System** (`internal/infrastructure/storage/`)
- **Archivo**: `local.go` (301 l√≠neas)
- **Tests**: `local_test.go` (9 tests - 100% PASS)
- **Caracter√≠sticas**:
  - SaveUpload con SHA256 hashing para idempotencia
  - GetUpload para recuperar archivos
  - SaveProcessedFile para cleaned/llm_input/llm_response
  - DeleteUpload con cleanup de directorios
  - CleanupOldFiles basado en tiempo
  - ListProcessedFiles para auditor√≠a
- **Estructura de directorios**:
  ```
  /tmp/uploads/
  ‚îú‚îÄ‚îÄ {uploadID}/original_file.xlsx
  /tmp/processed/
  ‚îú‚îÄ‚îÄ {uploadID}/
  ‚îÇ   ‚îú‚îÄ‚îÄ cleaned/cleaned_data.xlsx
  ‚îÇ   ‚îú‚îÄ‚îÄ llm_input/input.json
  ‚îÇ   ‚îî‚îÄ‚îÄ llm_response/response.json
  ```

#### 2. **Multi-Format File Parsers** (`internal/infrastructure/parsers/`)
- **Archivos creados**:
  - `types.go` - Interfaces y tipos base
  - `csv_parser.go` - Parser CSV con variable fields
  - `excel_parser.go` - Parser Excel con excelize/v2
  - `json_parser.go` - Parser JSON (array y objetos)
  - `jsonl_parser.go` - Parser JSONL/NDJSON/JSONNL
  - `parser_factory.go` - Factory pattern con auto-detecci√≥n
  - `parsers_test.go` - Suite completa de tests

- **Tests**: 27 tests - **100% PASS** ‚úÖ
  ```
  TestCSVParser_Parse ‚úì
  TestCSVParser_ParseStream ‚úì
  TestCSVParser_SkipEmptyRows ‚úì
  TestCSVParser_TrimWhitespace ‚úì
  TestCSVParser_MissingColumns ‚úì
  TestCSVParser_SupportedFormats ‚úì
  TestJSONParser_Parse ‚úì
  TestJSONParser_ParseStream ‚úì
  TestJSONParser_SupportedFormats ‚úì
  TestJSONLParser_Parse ‚úì
  TestJSONLParser_ParseStream ‚úì
  TestJSONLParser_SkipEmptyLines ‚úì
  TestJSONLParser_SkipMalformedLines ‚úì
  TestJSONLParser_SupportedFormats ‚úì
  TestJSONLParser_AllVariants (3 subtests) ‚úì
  TestParserFactory_GetParser (7 subtests) ‚úì
  TestParserFactory_GetParser_Unsupported ‚úì
  TestParserFactory_IsSupported ‚úì
  TestParserFactory_ParseFile (5 subtests) ‚úì
  TestParserFactory_SupportedFormats ‚úì
  TestParserConfig_MaxFileSize ‚úì
  TestContext_Cancellation ‚úì
  TestDefaultParserConfig ‚úì
  TestParseResult_Structure ‚úì
  ```

- **Formatos soportados**:
  - ‚úÖ CSV (`.csv`) - encoding/csv con fields variables
  - ‚úÖ Excel (`.xlsx`, `.xls`) - excelize/v2
  - ‚úÖ JSON (`.json`) - encoding/json
  - ‚úÖ JSONL (`.jsonl`) - Line-by-line streaming
  - ‚úÖ NDJSON (`.ndjson`) - Newline Delimited JSON
  - ‚úÖ JSONNL (`.jsonnl`) - JSON Newline variant

- **Caracter√≠sticas implementadas**:
  - **Streaming**: No carga archivos completos en memoria
  - **Context-aware**: Respeta context.Context para cancelaci√≥n
  - **Configurable**: MaxFileSize, SkipEmptyRows, TrimWhitespace
  - **Resiliente**: Maneja columnas faltantes, l√≠neas mal formadas
  - **Performance**: Buffers de 1MB para JSONL, reuso de slices

#### 3. **Dependencies agregadas**
```bash
go get github.com/xuri/excelize/v2  # Excel parsing
# Ya ten√≠amos: testify, GORM, go-redis, asynq
```

### üìä Progreso General

**Fase 1 (Core Infrastructure)**: ‚úÖ 100% Completada
- PostgreSQL + GORM
- Redis cache
- Asynq queue
- Domain models (7)
- Testing con testcontainers

**Fase 2 (Upload & Cleaning Pipeline)**: üîÑ 60% Completada
- ‚úÖ Storage local (9 tests)
- ‚úÖ File parsers (27 tests)
- ‚úÖ Refinery v1 (42 tests)
- ‚è≥ Deduplicaci√≥n (pendiente)
- ‚è≥ JSON generation para LLM (pendiente)

**Total de tests pasando**: 78 tests (9 storage + 27 parsers + 42 refinery)

### üéØ Pr√≥ximos pasos inmediatos

1. **Sistema de Deduplicaci√≥n** (Fase 2)
   - Implementar two-level deduplication
   - Nivel 1: Within batch (exact matching)
   - Nivel 2: Universal cross-session (DedupHash table)
   - Estrategias: exact, fuzzy, universal

2. **JSON Generation para LLM** (Fase 2)
   - Estructura optimizada para tokens
   - Incluir _row_index para tracking
   - Solo campos "clean" para reducir tama√±o
   - Metadata de contexto

3. **LLM Clients** (Fase 3)
   - OpenAI provider con sashabaranov/go-openai
   - Gemini provider con google/generative-ai-go
   - Factory pattern multi-proveedor
   - Retry logic y rate limiting

### üèóÔ∏è Arquitectura actual

```
backend/
‚îú‚îÄ‚îÄ internal/
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ domain/           ‚úÖ 7 models (GORM)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ refinery/         ‚úÖ v1 implementado (42 tests)
‚îÇ   ‚îî‚îÄ‚îÄ infrastructure/
‚îÇ       ‚îú‚îÄ‚îÄ database/         ‚úÖ PostgreSQL + GORM
‚îÇ       ‚îú‚îÄ‚îÄ cache/            ‚úÖ Redis
‚îÇ       ‚îú‚îÄ‚îÄ queue/            ‚úÖ Asynq
‚îÇ       ‚îú‚îÄ‚îÄ storage/          ‚úÖ Local storage (9 tests)
‚îÇ       ‚îî‚îÄ‚îÄ parsers/          ‚úÖ Multi-format (27 tests)
```

### üìù Decisiones t√©cnicas tomadas

1. **CSV Parser**: Usar `FieldsPerRecord = -1` para permitir columnas variables
2. **Excel Parser**: excelize/v2 por su madurez y soporte completo
3. **JSONL Variants**: Un solo parser maneja .jsonl, .ndjson, .jsonnl
4. **Streaming**: Buffers de 1MB para l√≠neas JSONL, 10K records default para CSV
5. **Error handling**: Skip de l√≠neas mal formadas, continuar procesamiento
6. **Storage paths**: Separaci√≥n clara entre uploads/ y processed/

### üîß Herramientas y librer√≠as en uso

- **GORM**: ORM completo para PostgreSQL
- **excelize/v2**: Parsing de Excel
- **go-redis/v9**: Cliente Redis
- **asynq**: Task queue
- **testify**: Assertions y require
- **testcontainers-go**: Integration tests con PostgreSQL real
- **slog**: Logging estructurado (stdlib)