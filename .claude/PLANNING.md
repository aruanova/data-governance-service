# Panel-Datainspector - Plan de RefactorizaciÃ³n (Monorepo)

## ðŸ“‹ Estado Actual
- **Stack Backend**: FastAPI + Celery + Redis + PostgreSQL + OpenAI
- **Stack Frontend**: Next.js 15.3.5 + React 19 + TypeScript
- **PropÃ³sito**: ClasificaciÃ³n de lÃ­neas CFDI usando LLM con refinamiento iterativo
- **Complejidad**: 12 routers, 25+ servicios, procesamiento async distribuido

## ðŸŽ¯ Objetivos de la RefactorizaciÃ³n
1. Migrar backend de Python/FastAPI a Go
2. Cambiar a Svelte con Skeleton (solo ajustar endpoints si es necesario)
3. Estructura monorepo para facilitar desarrollo
4. Mejorar performance y reducir uso de memoria
5. Simplificar arquitectura manteniendo funcionalidad completa

## ðŸ—ï¸ Estructura Monorepo Propuesta

```
data-governance-service/
â”œâ”€â”€ .claude/                    # DocumentaciÃ³n y contexto de Claude
â”‚   â”œâ”€â”€ PLANNING.md
â”‚   â””â”€â”€ CLAUDE.md
â”œâ”€â”€ backend/                    # Backend en Go
â”‚   â”œâ”€â”€ cmd/
â”‚   â”‚   â”œâ”€â”€ api/               # API REST server
â”‚   â”‚   â””â”€â”€ worker/            # Worker para procesamiento async
â”‚   â”œâ”€â”€ internal/
â”‚   â”‚   â”œâ”€â”€ api/               # HTTP handlers
â”‚   â”‚   â”‚   â”œâ”€â”€ handlers/      # Controladores REST
â”‚   â”‚   â”‚   â”œâ”€â”€ middleware/    # Auth, CORS, logging
â”‚   â”‚   â”‚   â””â”€â”€ websocket/     # WebSocket handlers
â”‚   â”‚   â”œâ”€â”€ core/              # Dominio central
â”‚   â”‚   â”‚   â”œâ”€â”€ models/        # Modelos de dominio
â”‚   â”‚   â”‚   â”œâ”€â”€ ports/         # Interfaces (hexagonal)
â”‚   â”‚   â”‚   â””â”€â”€ services/      # LÃ³gica de negocio
â”‚   â”‚   â”œâ”€â”€ infrastructure/    # Implementaciones externas
â”‚   â”‚   â”‚   â”œâ”€â”€ database/      # PostgreSQL
â”‚   â”‚   â”‚   â”œâ”€â”€ cache/         # Redis
â”‚   â”‚   â”‚   â”œâ”€â”€ storage/       # File system / S3
â”‚   â”‚   â”‚   â”œâ”€â”€ llm/           # OpenAI client
â”‚   â”‚   â”‚   â””â”€â”€ queue/         # Task queue (Asynq)
â”‚   â”‚   â””â”€â”€ pkg/               # Utilidades compartidas
â”‚   â”œâ”€â”€ migrations/            # SQL migrations
â”‚   â”œâ”€â”€ configs/               # Configuraciones
â”‚   â””â”€â”€ tests/                 # Tests de integraciÃ³n
â”œâ”€â”€ frontend/                  # Frontend (A definir si Svelte)
â”‚   â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ lib/
â”‚   â””â”€â”€ public/
â”œâ”€â”€ shared/                    # Compartido entre front y back
â”‚   â”œâ”€â”€ types/                # TypeScript types que matchean Go structs
â”‚   â””â”€â”€ api-spec/             # OpenAPI/Swagger specs
â”œâ”€â”€ scripts/                   # Scripts de build y deployment
â”œâ”€â”€ docker/                    # Dockerfiles y compose
â”œâ”€â”€ .github/                   # CI/CD workflows
â””â”€â”€ docs/                      # DocumentaciÃ³n del proyecto
```

## ðŸ”„ Servicios Go Propuestos

### 1. API Service (backend/cmd/api)
- **Responsabilidad**: Exponer REST API, manejar uploads, WebSockets
- **Puertos**: 8080 (HTTP), 8081 (WebSocket)
- **Similar a routers Python**: pipeline.py, cleaning.py, validation.py, batch.py

### 2. Worker Service (backend/cmd/worker)
- **Responsabilidad**: Procesar tareas async, LLM calls, batch processing
- **Similar a**: Celery workers actuales
- **Queue**: Asynq (Redis-based) o Temporal
- **Resiliencia**: Checkpointing, health checks, graceful shutdown

### 3. Servicios de Dominio (backend/internal/core/services)
```
services/
â”œâ”€â”€ upload/              # GestiÃ³n de uploads y archivos ZIP
â”œâ”€â”€ schema_inspector/    # InspecciÃ³n y anÃ¡lisis de archivos
â”œâ”€â”€ refinery/           # Sistema modular de limpieza de texto
â”‚   â”œâ”€â”€ v1_standard/    # VersiÃ³n para datos mexicanos
â”‚   â”œâ”€â”€ v2_aggressive/  # Limpieza mÃ¡s agresiva
â”‚   â””â”€â”€ registry/       # Registro de versiones
â”œâ”€â”€ cleaning/           # Limpieza y deduplicaciÃ³n
â”‚   â”œâ”€â”€ deduplication/  # Sistema two-level de dedup
â”‚   â””â”€â”€ json_generator/ # Generador de JSON para LLM
â”œâ”€â”€ prompts/            # GestiÃ³n de prompts customizables
â”‚   â”œâ”€â”€ storage/        # Almacenamiento de prompts
â”‚   â””â”€â”€ versioning/     # Versionado de prompts
â”œâ”€â”€ llm/               # ClasificaciÃ³n con LLM
â”œâ”€â”€ validation/        # Muestreo y validaciÃ³n
â”œâ”€â”€ batch/             # Procesamiento multi-archivo
â”œâ”€â”€ iteration/         # Tracking de iteraciones
â”œâ”€â”€ metrics/           # Captura de mÃ©tricas
â”œâ”€â”€ checkpoint/        # Sistema de checkpointing
â”œâ”€â”€ recovery/          # RecuperaciÃ³n de trabajos fallidos
â””â”€â”€ session/           # GestiÃ³n de sesiones
```

## ðŸ“Š Flujo de Procesamiento de Archivos

### Pipeline Pre-LLM
```mermaid
graph LR
    A[Upload ZIP] --> B[Schema Inspection]
    B --> C[Refinery Cleaning]
    C --> D[Deduplication]
    D --> E[JSON Generation]
    E --> F[LLM Processing]
```

### Etapas Detalladas

#### 1. Upload & ExtracciÃ³n
- RecepciÃ³n de archivos ZIP con mÃºltiples formatos
- Soporte para: CSV, XLSX, JSON, JSONL, NDJSON, JSONNL
- Streaming para archivos grandes
- ValidaciÃ³n de esquemas

#### 2. Schema Inspection
- DetecciÃ³n automÃ¡tica de columnas
- Inferencia de tipos de datos
- AnÃ¡lisis de calidad de datos
- Sampling para preview

#### 3. Refinery (Sistema Modular)
- **Arquitectura Plugin**: Versiones intercambiables
- **v1-standard**: Limpieza para datos mexicanos
- **v2-aggressive**: Limpieza mÃ¡s estricta
- **Nodos de Procesamiento**:
  - Remover cÃ³digos con prefijos (ART###)
  - Remover meses en espaÃ±ol
  - NormalizaciÃ³n de caracteres especiales
  - Remover palabras cortas
  - Aplicar whitelist/blacklist

#### 4. DeduplicaciÃ³n Two-Level
- **Nivel 1**: DeduplicaciÃ³n dentro del batch
- **Nivel 2**: DeduplicaciÃ³n universal (cross-session)
- Estrategias: exact, fuzzy, universal
- Usa columnas "clean" generadas por Refinery

#### 5. JSON Generation
- CreaciÃ³n de estructura optimizada para LLM
- InclusiÃ³n de _row_index para tracking
- Solo campos "clean" para reducir tokens
- Metadata para contexto

## ðŸ¤– Sistema Multi-Proveedor LLM

### Proveedores Soportados
- **OpenAI**: GPT-4, GPT-4o-mini, GPT-3.5-turbo
- **Google Gemini**: Gemini-Pro, Gemini-1.5-Pro
- **Extensible**: Factory pattern para agregar nuevos proveedores

### CaracterÃ­sticas
- **SelecciÃ³n DinÃ¡mica**: Usuario escoge proveedor por request
- **Fallback AutomÃ¡tico**: Si un proveedor falla, notificar al usuario y darle a escoger usar una alternativa
- **ConfiguraciÃ³n por Proveedor**:
  - API Keys independientes
  - Modelos especÃ­ficos
  - Rate limits y retry policies
- **MÃ©tricas Comparativas**:
  - Tiempo de respuesta
  - Costo por tokens
  - Calidad de clasificaciÃ³n

## ðŸŽ¨ Sistema de Prompts Customizables

### CaracterÃ­sticas Clave
- **100% Customizable**: NO hay prompt default
- **GestiÃ³n de Prompts**:
  - Crear, editar, eliminar prompts
  - Asignar labels descriptivos
  - Versionado automÃ¡tico
  - Compartir entre usuarios
- **CategorÃ­as DinÃ¡micas**:
  - Usuario define sus propias categorÃ­as
  - Puede importar/exportar sets de categorÃ­as
  - Prioridades configurables
- **Storage**:
  - PostgreSQL para persistencia
  - Redis para cache
  - Historial de versiones

### Estructura de Prompt
```json
{
  "id": "uuid",
  "name": "Mi Prompt OXXO v3",
  "label": "ClasificaciÃ³n gastos OXXO 2024",
  "template": "Texto del prompt customizado...",
  "categories": [
    {
      "id": 1,
      "name": "CategorÃ­a Custom 1",
      "description": "DescripciÃ³n",
      "keywords": ["palabra1", "palabra2"]
    }
  ],
  "created_by": "user_id",
  "version": 3,
  "is_active": true
}
```

## ðŸ“Š Fases de MigraciÃ³n

### Fase 0: Setup Monorepo âœ… COMPLETADA
- [x] Crear estructura .claude
- [x] Definir estructura de carpetas
- [x] Setup Go modules
- [x] Configurar herramientas (air para hot reload)
- [ ] Docker Compose para desarrollo (pendiente)

### Fase 1: Core Infrastructure âœ… COMPLETADA
- [x] ConexiÃ³n PostgreSQL con GORM (cambio de pgx a GORM)
- [x] ConexiÃ³n Redis (go-redis/v9)
- [x] Logging estructurado (slog)
- [x] Config management (viper)
- [x] Migrations setup (SQL migrations manuales)
- [x] Task Queue (Asynq)
- [x] Domain models (7 modelos con GORM)
- [x] Testing setup (testcontainers-go con PostgreSQL)

### Fase 2: Upload & Cleaning Pipeline âœ… COMPLETADA (100%)
- [x] Storage local para uploads (FileMetadata, SHA256 hashing, cleanup - 9 tests)
- [x] Parsers de archivos multi-formato (CSV, Excel, JSON, JSONL, NDJSON, JSONNL - 27 tests)
- [x] Parsing streaming de archivos grandes (buffers configurables, context-aware)
- [x] Pipeline de limpieza (Refinery v1 - 42 tests pasando)
- [x] DeduplicaciÃ³n universal (two-level: batch + cross-session - 10 tests)
- [x] GeneraciÃ³n de JSON para LLM (21 tests - token-optimized, chunking, validation)

### Fase 3: LLM Integration (Semana 5-6)
- [ ] Cliente OpenAI
- [ ] Cliente Gemini
- [ ] Chunking dinÃ¡mico configurable (LLM_DISTRIBUTED_CHUNK_SIZE)
- [ ] Worker pool configurable para procesamiento paralelo
- [ ] Manejo de respuestas y normalizaciÃ³n
- [ ] Count mismatch handling
- [ ] Retry logic con backoff

### Fase 4: Task Queue System âš ï¸ PARCIAL
- [x] Setup Asynq (ya implementado en Fase 1)
- [ ] Migrar lÃ³gica de Celery tasks
- [ ] Progress tracking
- [ ] WebSocket updates

### Fase 5: Validation & Refinement (Semana 9-10)
- [ ] Sampling strategies
- [ ] Validation submission
- [ ] Prompt refinement
- [ ] Iteration tracking
- [ ] Comparative metrics

### Fase 6: Batch Processing (Semana 11-12)
- [ ] Directory scanning
- [ ] Schema validation
- [ ] Multi-file processing
- [ ] Consolidation
- [ ] Streaming para archivos grandes

## ðŸ› ï¸ Stack TecnolÃ³gico Definitivo

### Backend (Go)
- **Web Framework**: Gin
- **Task Queue**: Asynq (simple, Redis)
- **Database**: GORM (ORM completo)
- **Cache**: go-redis/v9
- **LLM Providers**:
  - OpenAI: sashabaranov/go-openai
  - Gemini: google/generative-ai-go
  - Factory Pattern para multi-proveedor
- **Excel**: excelize/v2
- **Validation**: go-playground/validator/v10
- **Config**: spf13/viper
- **Logging**: slog (stdlib)
- **Metrics**: Prometheus

### Infraestructura
- **PostgreSQL**: v15+ (igual que actual)
- **Redis**: v7+ (igual que actual)
- **Docker**: Multi-stage builds
- **CI/CD**: GitHub Actions

## â“ Decisiones TÃ©cnicas Pendientes

### Alta Prioridad
1. **Web Framework**:
   - Gin (popular, buen balance)

2. **Task Queue**:
   - Asynq (simple, suficiente para el caso)

3. **SQL Approach**:
   - GORM (ORM completo)

### Media Prioridad âœ… RESUELTAS
4. **Estructura del cÃ³digo**:
   - âœ… Hexagonal/Clean Architecture (implementada)

5. **Testing Strategy**:
   - âœ… testify para assertions (implementado)
   - â³ mockery para mocks (pendiente)
   - âœ… testcontainers para integration (implementado)

## ðŸŽ¯ Optimizaciones Clave vs Python

### Performance
```go
// Streaming de archivos grandes sin cargar en memoria
func ProcessLargeFile(reader io.Reader) error {
    scanner := bufio.NewScanner(reader)
    batch := make([]Record, 0, 1000)

    for scanner.Scan() {
        record := ParseRecord(scanner.Text())
        batch = append(batch, record)

        if len(batch) >= 1000 {
            processBatch(batch)
            batch = batch[:0] // reuse slice
        }
    }
}
```

### Concurrencia Real
```go
// Procesamiento paralelo de chunks con workers pool
func ProcessChunks(chunks []Chunk) {
    workers := runtime.NumCPU()
    ch := make(chan Chunk, len(chunks))
    var wg sync.WaitGroup

    // Worker pool
    for i := 0; i < workers; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            for chunk := range ch {
                processWithLLM(chunk)
            }
        }()
    }

    // Feed work
    for _, chunk := range chunks {
        ch <- chunk
    }
    close(ch)
    wg.Wait()
}
```

## ðŸ“ˆ MÃ©tricas de Ã‰xito
- [ ] 50% reducciÃ³n en uso de memoria
- [ ] 2x mejora en throughput
- [ ] <100ms latencia P95 en API
- [ ] 80% cobertura de tests
- [ ] Zero downtime durante migraciÃ³n

## ðŸš€ PrÃ³ximos Pasos Inmediatos
1. âœ… Crear estructura .claude
2. Definir decisiones tÃ©cnicas clave
3. Crear CLAUDE.md con convenciones
4. Setup inicial del proyecto Go
5. Implementar primer endpoint como POC

## ðŸ“ Notas Importantes
- Frontend se rediseÃ±a con Svelte/Skeleton
- API debe mantener compatibilidad con frontend actual
- Aprovechar monorepo para compartir tipos/specs
- Deployment serÃ¡ en AWS/GCP

---

## ðŸŽ¯ CHECKPOINT #2 - File Processing & Parsers (17 Oct 2025)

### âœ… Completado en esta sesiÃ³n

#### 1. **Local Storage System** (`internal/infrastructure/storage/`)
- **Archivo**: `local.go` (301 lÃ­neas)
- **Tests**: `local_test.go` (9 tests - 100% PASS)
- **CaracterÃ­sticas**:
  - SaveUpload con SHA256 hashing para idempotencia
  - GetUpload para recuperar archivos
  - SaveProcessedFile para cleaned/llm_input/llm_response
  - DeleteUpload con cleanup de directorios
  - CleanupOldFiles basado en tiempo
  - ListProcessedFiles para auditorÃ­a
- **Estructura de directorios**:
  ```
  /tmp/uploads/
  â”œâ”€â”€ {uploadID}/original_file.xlsx
  /tmp/processed/
  â”œâ”€â”€ {uploadID}/
  â”‚   â”œâ”€â”€ cleaned/cleaned_data.xlsx
  â”‚   â”œâ”€â”€ llm_input/input.json
  â”‚   â””â”€â”€ llm_response/response.json
  ```

#### 2. **Multi-Format File Parsers** (`internal/infrastructure/parsers/`)
- **Archivos creados**:
  - `types.go` - Interfaces y tipos base
  - `csv_parser.go` - Parser CSV con variable fields
  - `excel_parser.go` - Parser Excel con excelize/v2
  - `json_parser.go` - Parser JSON (array y objetos)
  - `jsonl_parser.go` - Parser JSONL/NDJSON/JSONNL
  - `parser_factory.go` - Factory pattern con auto-detecciÃ³n
  - `parsers_test.go` - Suite completa de tests

- **Tests**: 27 tests - **100% PASS** âœ…
  ```
  TestCSVParser_Parse âœ“
  TestCSVParser_ParseStream âœ“
  TestCSVParser_SkipEmptyRows âœ“
  TestCSVParser_TrimWhitespace âœ“
  TestCSVParser_MissingColumns âœ“
  TestCSVParser_SupportedFormats âœ“
  TestJSONParser_Parse âœ“
  TestJSONParser_ParseStream âœ“
  TestJSONParser_SupportedFormats âœ“
  TestJSONLParser_Parse âœ“
  TestJSONLParser_ParseStream âœ“
  TestJSONLParser_SkipEmptyLines âœ“
  TestJSONLParser_SkipMalformedLines âœ“
  TestJSONLParser_SupportedFormats âœ“
  TestJSONLParser_AllVariants (3 subtests) âœ“
  TestParserFactory_GetParser (7 subtests) âœ“
  TestParserFactory_GetParser_Unsupported âœ“
  TestParserFactory_IsSupported âœ“
  TestParserFactory_ParseFile (5 subtests) âœ“
  TestParserFactory_SupportedFormats âœ“
  TestParserConfig_MaxFileSize âœ“
  TestContext_Cancellation âœ“
  TestDefaultParserConfig âœ“
  TestParseResult_Structure âœ“
  ```

- **Formatos soportados**:
  - âœ… CSV (`.csv`) - encoding/csv con fields variables
  - âœ… Excel (`.xlsx`, `.xls`) - excelize/v2
  - âœ… JSON (`.json`) - encoding/json
  - âœ… JSONL (`.jsonl`) - Line-by-line streaming
  - âœ… NDJSON (`.ndjson`) - Newline Delimited JSON
  - âœ… JSONNL (`.jsonnl`) - JSON Newline variant

- **CaracterÃ­sticas implementadas**:
  - **Streaming**: No carga archivos completos en memoria
  - **Context-aware**: Respeta context.Context para cancelaciÃ³n
  - **Configurable**: MaxFileSize, SkipEmptyRows, TrimWhitespace
  - **Resiliente**: Maneja columnas faltantes, lÃ­neas mal formadas
  - **Performance**: Buffers de 1MB para JSONL, reuso de slices

#### 3. **Dependencies agregadas**
```bash
go get github.com/xuri/excelize/v2  # Excel parsing
# Ya tenÃ­amos: testify, GORM, go-redis, asynq
```

### ðŸ“Š Progreso General

**Fase 1 (Core Infrastructure)**: âœ… 100% Completada
- PostgreSQL + GORM
- Redis cache
- Asynq queue
- Domain models (7)
- Testing con testcontainers

**Fase 2 (Upload & Cleaning Pipeline)**: ðŸ”„ 60% Completada
- âœ… Storage local (9 tests)
- âœ… File parsers (27 tests)
- âœ… Refinery v1 (42 tests)
- â³ DeduplicaciÃ³n (pendiente)
- â³ JSON generation para LLM (pendiente)

**Total de tests pasando**: 78 tests (9 storage + 27 parsers + 42 refinery)

### ðŸŽ¯ PrÃ³ximos pasos inmediatos

1. **Sistema de DeduplicaciÃ³n** (Fase 2)
   - Implementar two-level deduplication
   - Nivel 1: Within batch (exact matching)
   - Nivel 2: Universal cross-session (DedupHash table)
   - Estrategias: exact, fuzzy, universal

2. **JSON Generation para LLM** (Fase 2)
   - Estructura optimizada para tokens
   - Incluir _row_index para tracking
   - Solo campos "clean" para reducir tamaÃ±o
   - Metadata de contexto

3. **LLM Clients** (Fase 3)
   - OpenAI provider con sashabaranov/go-openai
   - Gemini provider con google/generative-ai-go
   - Factory pattern multi-proveedor
   - Retry logic y rate limiting

### ðŸ—ï¸ Arquitectura actual

```
backend/
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ domain/           âœ… 7 models (GORM)
â”‚   â”‚   â””â”€â”€ refinery/         âœ… v1 implementado (42 tests)
â”‚   â””â”€â”€ infrastructure/
â”‚       â”œâ”€â”€ database/         âœ… PostgreSQL + GORM
â”‚       â”œâ”€â”€ cache/            âœ… Redis
â”‚       â”œâ”€â”€ queue/            âœ… Asynq
â”‚       â”œâ”€â”€ storage/          âœ… Local storage (9 tests)
â”‚       â””â”€â”€ parsers/          âœ… Multi-format (27 tests)
```

### ðŸ“ Decisiones tÃ©cnicas tomadas

1. **CSV Parser**: Usar `FieldsPerRecord = -1` para permitir columnas variables
2. **Excel Parser**: excelize/v2 por su madurez y soporte completo
3. **JSONL Variants**: Un solo parser maneja .jsonl, .ndjson, .jsonnl
4. **Streaming**: Buffers de 1MB para lÃ­neas JSONL, 10K records default para CSV
5. **Error handling**: Skip de lÃ­neas mal formadas, continuar procesamiento
6. **Storage paths**: SeparaciÃ³n clara entre uploads/ y processed/

### ðŸ”§ Herramientas y librerÃ­as en uso

- **GORM**: ORM completo para PostgreSQL
- **excelize/v2**: Parsing de Excel
- **go-redis/v9**: Cliente Redis
- **asynq**: Task queue
- **testify**: Assertions y require
- **testcontainers-go**: Integration tests con PostgreSQL real
- **slog**: Logging estructurado (stdlib)